#!/usr/bin/env python
# -*- encoding: utf-8 -*-
# Created on 2015-07-06 15:26:32
# Project: com21cn_v5

from pyspider.libs.base_handler import *
import re
import json
import urllib
from pyspider.image_server import *

class Handler(BaseHandler):
    crawl_config = {
        "headers":{
            "User-Agent": "Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/43.0.2357.132 Safari/537.36",
        },
        "force_update":True,
    }

    @every(minutes=3 * 60)
    def on_start(self):
        self.crawl('http://auto.21cn.com/autonews/', callback=self.index_page)
        self.crawl('http://auto.21cn.com/autonews/list2.shtml', callback=self.index_page)
        self.crawl('http://auto.21cn.com/yongche/', callback=self.index_page)
        self.crawl('http://auto.21cn.com/yongche/list2.shtml', callback=self.index_page)
        self.crawl('http://auto.21cn.com/wenhua/', callback=self.index_page)
        self.crawl('http://auto.21cn.com/wenhua/list2.shtml', callback=self.index_page)
        self.crawl('http://auto.21cn.com/wenhua/shenghuo/', callback=self.index_page)
        self.crawl('http://auto.21cn.com/wenhua/shenghuo/list2.shtml', callback=self.index_page)
        self.crawl('http://auto.21cn.com/gouche/', callback=self.index_page)
        self.crawl('http://auto.21cn.com/gouche/list2.shtml', callback=self.index_page)
        self.crawl('http://auto.21cn.com/zixun/', callback=self.index_page)
        self.crawl('http://auto.21cn.com/zixun/list2.shtml', callback=self.index_page)
        self.crawl('http://auto.21cn.com/gouche/hangqing/', callback=self.index_page)
        self.crawl('http://auto.21cn.com/gouche/hangqing/list2.shtml', callback=self.index_page)
        self.crawl('http://auto.21cn.com/zixun/zhuanlan/', callback=self.index_page)
        self.crawl('http://auto.21cn.com/zixun/zhuanlan/list2.shtml', callback=self.index_page)
        
        
        
    @config(age=10 * 24 * 60 * 60)
    def index_page(self, response):
        for each in response.doc('.clearfix > div > .bigPic > h3 > a[href^="http"]').items():
            self.crawl(each.attr.href, callback=self.detail_page)

    @config(priority=2)
    def detail_page(self, response):
        g = re.search(ur'作者：(.*)',response.doc('.infoAuthor').text())
        author = ""
        if g is not None:
            author = g.group(1)
        detail = {
            "url": response.url,
            "title": response.doc('.title').text(),
            "news": clean(response.doc('#article_text').html()),
            "images": [x.attr("src") for x in response.doc("#article_text img").items()],
            "source": response.doc('td > a').text(),
            "date": response.doc('.pubTime').text(),
            "author": author,
        }
        next = response.doc('.page-ctrl a:last')
        if next.text() == u'下一页':
            self.crawl(next.attr.href, callback=self.next_page, save = detail)
        else:
            return extract_info(detail)
    
    @config(priority=1)
    def next_page(self, response):
        detail = response.save
        detail["news"] += clean(response.doc('#article_text').html())
        detail["images"] += [x.attr("src") for x in response.doc("#article_text img").items()]
        next = response.doc('.page-ctrl a:last')
        if next.text() == u'下一页':
            self.crawl(next.attr.href, callback=self.next_page, save = detail)
        else:
           return extract_info(detail)
